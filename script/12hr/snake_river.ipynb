{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><!--input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"--></form>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "   $('div.input').hide()\n",
    "    $('div.prompt').hide();\n",
    "    $('div.back-to-top').hide();\n",
    "    $('nav#menubar').hide();\n",
    "    $('.breadcrumb').hide();\n",
    "    $('.hidden-print').hide();\n",
    "  });\n",
    "</script>\n",
    "\n",
    "<footer id=\"attribution\" style=\"float:right; color:#999; background:#fff;\">\n",
    "\n",
    "</footer>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  jQuery(document).ready(function($) {\n",
    "  \n",
    "  $(window).load(function(){\n",
    "    $('#preloader').fadeOut('slow',function(){$(this).remove();});\n",
    "  });\n",
    "    \n",
    "  });\n",
    "</script>\n",
    "\n",
    "<style type=\"text/css\">\n",
    "  div#preloader { position: fixed;\n",
    "      left: 0;\n",
    "      top: 0;\n",
    "      z-index: 999;\n",
    "      width: 100%;\n",
    "      height: 100%;\n",
    "      overflow: visible;\n",
    "      background: #fff url('http://preloaders.net/preloaders/720/Moving%20line.gif') no-repeat center center;\n",
    "  }\n",
    "\n",
    "</style>\n",
    "\n",
    "<div id=\"preloader\"></div>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "  $(document).ready(function(){\n",
    "  $(\"#T_data_table\").addClass('data');\n",
    "  $(\"#T_header-fixed\").addClass('data')\n",
    "   });\n",
    "</script>\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "$(document).ready(function(){\n",
    "var tableOffset = $(\"#T_data_table\").offset().top;\n",
    "var $header = $(\"#T_data_table > thead\").clone();\n",
    "var $fixedHeader = $(\"#T_header-fixed\").append($header);\n",
    "\n",
    "$(window).bind(\"scroll\", function() {\n",
    "    var offset = $(this).scrollTop();\n",
    "    \n",
    "    if (offset >= tableOffset && $fixedHeader.is(\":hidden\")) {\n",
    "        $fixedHeader.show();\n",
    "    }\n",
    "    else if (offset < tableOffset) {\n",
    "        $fixedHeader.hide();\n",
    "    }\n",
    "});\n",
    "});\n",
    "</script>\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<style type ='text/css'>\n",
    "\n",
    "\n",
    ".container {\n",
    "    width: 99% !important;\n",
    "}   \n",
    "\n",
    "div.cell.selected {\n",
    "    border-left-width: 1px !important;\t\n",
    "}\n",
    "\n",
    "div {\n",
    "    resize: none !important;\n",
    "}\n",
    "\n",
    "\n",
    "#T_header-fixed { \n",
    "    position: fixed; \n",
    "    top: 0px; display:none;\n",
    "    background-color:white;\n",
    "    padding: 0px; margin:0;\n",
    "    width: 95em\n",
    "    \n",
    "}\n",
    "\n",
    ".data thead tr:nth-child(1) th:nth-child(1){\n",
    "    width:90px;\n",
    "}\n",
    "\n",
    ".data thead tr:nth-child(1) th:nth-child(2){\n",
    "    width:389px;\n",
    "}\n",
    "\n",
    ".data thead tr:nth-child(1) th:nth-child(3){\n",
    "    width:389px;\n",
    "}\n",
    "\n",
    ".data thead tr:nth-child(1) th:nth-child(4){\n",
    "    width:389px;\n",
    "}\n",
    "\n",
    ".data thead tr:nth-child(1) th:nth-child(5){\n",
    "    width:445px;\n",
    "}\n",
    "\n",
    ".data thead{\n",
    "    border:5px solid #000;\n",
    "\n",
    "}\n",
    "\n",
    ".data thead tr:first-of-type{\n",
    "    border: 2px solid #000;\n",
    "}\n",
    "\n",
    ".data tbody{\n",
    "    border: 2px solid #000\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    ".data th{\n",
    "    text-align: center;\n",
    "    border-left:2px solid #000;\n",
    "    border-right:2px solid #000;\n",
    "\n",
    "}\n",
    "\n",
    ".data th:first-child{\n",
    "    border-left: none;\n",
    "\n",
    "}\n",
    "\n",
    ".data td{\n",
    "    text-align: center;\n",
    "    border-collapse: collapse;\n",
    "    border-left: 1px solid #000;\n",
    "    border-right: 1px solid #000;\n",
    "}\n",
    "\n",
    "#T_data_table tbody:caption{\n",
    "    caption-side: bottom;\n",
    "}\n",
    "\n",
    "#T_data_table{\n",
    "    width: 95em;\n",
    "}\n",
    "\n",
    ".highlighted {\n",
    "    background-color: #ffff99;\n",
    "}\n",
    "\n",
    "\n",
    "#T_key th{\n",
    "    text-align:left;\n",
    "}\n",
    "#T_key td{\n",
    "    text-align:center;\n",
    "}\n",
    "#T_key thead th{\n",
    "   border:2px solid #000;\n",
    "}\n",
    "\n",
    "table { \n",
    "    table-layout:fixed; !important\n",
    "}\n",
    "\n",
    "\n",
    ".rendered_html h1 {\n",
    "    font-size: 250%;\n",
    "    margin: 1.08em 0 0 0;\n",
    "    font-weight: bold;\n",
    "    line-height: 1.0;\n",
    "\n",
    "\n",
    "\n",
    "img {\n",
    "padding-right:30px\n",
    "}\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<script>\n",
    "$(document).ready(function(){\n",
    "$('td').hover(function() {\n",
    "    var t = parseInt($(this).index()) + 1;\n",
    "    $('#T_data_table thead tr:not(:first-child) th:nth-child(' + t + ')').addClass('highlighted');\n",
    "    $('#T_header-fixed thead tr:not(:first-child) th:nth-child(' + t + ')').addClass('highlighted');\n",
    "},\n",
    "function() {\n",
    "    var t = parseInt($(this).index()) + 1;\n",
    "    \n",
    "    $('th:nth-child(' + t + ')').removeClass('highlighted');\n",
    "});\n",
    "});\n",
    "</script>\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "<img src=\"usace_logo.png\" style=\"float: left;\" width = 150>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "from numpy import median\n",
    "\n",
    "\n",
    "def reindex(df, start_date, end_date, freq):\n",
    "    start = datetime(*start_date)\n",
    "    end = datetime(*end_date)\n",
    "    end = end.replace(hour = 23, minute = 0, second = 0)\n",
    "    date = pd.date_range(start, end, freq = freq)\n",
    "    date = [pd.Timestamp(x) for x in date]\n",
    "    if 'D' in freq:\n",
    "        index = df.index.copy()\n",
    "        index_hours = [x.hour for x in index]\n",
    "        m = median(index_hours)\n",
    "        def find_remainder(x):\n",
    "            return x%m\n",
    "        if sum([x%m for x in index_hours])>0:\n",
    "            return False\n",
    "        else:\n",
    "            date = [x.replace(hour = int(m)) for x in date] \n",
    "    df = df.reindex(date)\n",
    "    df.index.rename('date', inplace = True)\n",
    "    return df\n",
    "\n",
    "def get_frequency(index: pd.core.indexes.datetimes.DatetimeIndex)->str:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        \n",
    "        index: a pd.core.indexes.datetimes.DatetimeIndex from a timeseries\n",
    "        \n",
    "    Returns:\n",
    "        \n",
    "        freq: a string value of either a daily, hourly, minutely, or secondly \n",
    "              Offset Alias with the appropriate multiple.\n",
    "              This is not very robust, and returns False if it is not able to \n",
    "              easily determine the frequency\n",
    "    \"\"\"\n",
    "    seconds = index.to_series().diff().median().total_seconds()\n",
    "    minutes = seconds/60\n",
    "    hours = minutes/60\n",
    "    days = hours/24\n",
    "    if days>=1 and days%int(days) == 0:\n",
    "        freq = str(int(days))+'D'\n",
    "    elif hours>=1 and hours%int(hours) == 0:\n",
    "        freq = str(int(hours))+'H'\n",
    "    elif minutes>=1 and minutes%int(minutes) == 0:\n",
    "        freq = str(int(minutes))+'min'\n",
    "    elif seconds>=1 and seconds%int(seconds) == 0:\n",
    "        freq = str(int(seconds))+'S'\n",
    "    else: \n",
    "        freq =  False\n",
    "    return freq\n",
    "    \n",
    "    \n",
    "def time_window_url(paths, public=True, lookback = 7, start_date = False, end_date = False, timezone = 'PST'):\n",
    "    \"\"\"\n",
    "    helper function for cwms_read\n",
    "    \n",
    "    Arguments:  \n",
    "        \n",
    "        path -- cwms data path, \n",
    "        public -- boolean, \n",
    "        start_date -- date integer tuple format (YYYY, m, d)\n",
    "        end_date -- date integer tuple format (YYYY, m, d)\n",
    "        timezone -- optional keyword argument if time zone is specified.  \n",
    "                    Defaults to 'PST' if nothing set\n",
    "    Returns:\n",
    "        \n",
    "        url -- url string of CWMS data webservice for the specified \n",
    "               data path and time window\n",
    "               \n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(paths, list): \n",
    "        path = '%22%2C%22'.join(paths)\n",
    "    else: path = paths\n",
    "        \n",
    "    if public:\n",
    "        url = r'http://pweb.crohms.org/dd/common/web_service/webexec/getjson?timezone=TIMEZONE_&query=%5B%22PATH%22%5D&'\n",
    "    else:\n",
    "        url = r'http://nwp-wmlocal2.nwp.usace.army.mil/common/web_service/webexec/getjson?timezone=TIMEZONE_&query=%5B%22PATH%22%5D&'\n",
    "    \n",
    "    url = url.replace('PATH', path).replace('TIMEZONE_', timezone)\n",
    "    if lookback:\n",
    "        time = 'backward=' + str(lookback) + 'd'\n",
    "        url = url + time\n",
    "    else:\n",
    "        url = url + 'startdate=START_MONTH%2FSTART_DAY%2FSTART_YEAR+00%3A00&enddate=END_MONTH%2FEND_DAY%2FEND_YEAR+23%3A00'\n",
    "        sy,sm,sd = start_date\n",
    "        start_date = datetime(sy,sm,sd)\n",
    "        ey,em,ed = end_date\n",
    "        end_date = datetime(ey,em,ed)\n",
    "        url = url.replace('START_MONTH', str(start_date.month)).replace('START_DAY', str(start_date.day)).replace('START_YEAR', str(start_date.year))\n",
    "        url = url.replace('END_MONTH', str(end_date.month)).replace('END_DAY', str(end_date.day)).replace('END_YEAR', str(end_date.year))\n",
    "    \n",
    "    return url\n",
    "\n",
    "    \n",
    "\n",
    "def get_cwms(paths, public = True, fill = True, set_day = True, **kwargs):\n",
    "    \n",
    "    \"\"\"\n",
    "    A function to parse CWMS json data from webservice into a pandas dataframe\n",
    "        \n",
    "    Positional Arguments: \n",
    "        paths -- single string or list of string of CWMS data paths, example: 'TDDO.Temp-Water.Inst.1Hour.0.GOES-REV' \n",
    "    Keyword Arguments:\n",
    "        \n",
    "        The web service can either get a lookback, which is just a number of \n",
    "        days from the current day, or a time window.  Two key word arguments are \n",
    "        needed for a time wondow, start_date, end_date.  The Timezone can also\n",
    "        be set.\n",
    "        \n",
    "        lookback    --  The number of days from current day to grab data.\n",
    "                        (int or str) \n",
    "                        example: 7\n",
    "                        \n",
    "        start_date  --  The start of a time window (tuple) formatted \n",
    "                        (year, month, day)\n",
    "                        example: (2017, 3, 22)\n",
    "                        \n",
    "        end_date    --  The end of a time window (tuple) formatted \n",
    "                        (year, month, day)\n",
    "                        example: (2017, 3, 22)\n",
    "        \n",
    "        timezone    --  \"PST\", \"PDT\", \"MST\", \"MDT\", \"GMT\"\n",
    "                        \n",
    "                        \n",
    "    Returns:\n",
    "        \n",
    "        df -- A pandas dataframe with metadata from the webservice is returned.  \n",
    "              Metadata is stored in df.__dict__['metadata'], the data is used in \n",
    "              some of the plotting functions.  The metadata is easily lost if a df\n",
    "              is copied or transformed in some way.  It may be best to export the \n",
    "              metadata if it is needed.  meta = df.__dict__['metadata']\n",
    "        \n",
    "        \n",
    "    \"\"\"\n",
    "    try: \n",
    "        lookback = kwargs['lookback']\n",
    "        start_date = False\n",
    "        end_date = False\n",
    "    except:\n",
    "        lookback = False\n",
    "        start_date = kwargs['start_date']\n",
    "        end_date = kwargs['end_date']\n",
    "    try:timezone = kwargs['timezone']\n",
    "    except: timezone = 'PST'\n",
    "    url = time_window_url(paths,start_date=start_date, end_date=end_date, lookback = lookback, public=public,timezone = timezone)\n",
    "    r = requests.get(url)\n",
    "    json_data = json.loads(r.text)\n",
    "    df_list = []\n",
    "    meta = {}\n",
    "    if not isinstance(paths, list):\n",
    "        paths = [paths]\n",
    "    site_dict = {}\n",
    "    for path in paths:\n",
    "        site = path.split('.')[0]\n",
    "        try: site_dict[site].append(path)\n",
    "        except KeyError:\n",
    "            site_dict.update({site:[path]})\n",
    "            \n",
    "    for site,path_list in site_dict.items():\n",
    "        try:\n",
    "            data = json_data[site]\n",
    "        except KeyError:\n",
    "            sys.stderr.write('No data for %s\\n' % site)\n",
    "            continue\n",
    "        lat = data['coordinates']['latitude']\n",
    "        long = data['coordinates']['longitude']\n",
    "        tz_offset = data['tz_offset']\n",
    "        tz = data['timezone']\n",
    "        for path in path_list:\n",
    "            vals = data['timeseries'][path.strip()]\n",
    "            column_name = '_'.join(path.split('.')[:2])\n",
    "            column_name = '_'.join(column_name.split('-'))\n",
    "            try:path_data = vals['values']\n",
    "            except KeyError: \n",
    "                sys.stderr.write('!No data for %s\\n' % path)\n",
    "                continue\n",
    "            date = [val[0] for val in path_data]\n",
    "            values = [val[1] for val in path_data]\n",
    "            flags = [val[2] for val in path_data]\n",
    "            df= pd.DataFrame({'date': date, column_name: values})\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "            flags = pd.DataFrame({'date': df['date'], 'flag': flags})\n",
    "            flags = flags[flags['flag']>0].set_index('date')\n",
    "            df.set_index('date', inplace = True)\n",
    "            freq = get_frequency(df.index)\n",
    "            if freq and 'D' in freq and set_day:\n",
    "                df.index = [x.replace(hour = 0, minute = 0, second = 0) for x in df.index]\n",
    "                df.index.name = 'date'\n",
    "            df_list.append(df)\n",
    "            vals.pop('values', None)\n",
    "            vals.update({'path':path, 'lat':lat,'long':long, \n",
    "                         'tz_offset':tz_offset, 'timezone':tz, 'flags': flags})\n",
    "            meta.update({column_name:vals})\n",
    "    \n",
    "    if not df_list: return False\n",
    "    else: df = pd.concat(df_list, axis = 1)\n",
    "    \n",
    "    if fill:\n",
    "        try:\n",
    "            freq = kwargs['freq']\n",
    "        except KeyError:\n",
    "            freq = get_frequency(df.index)\n",
    "        if not freq:\n",
    "            sys.stderr.write('Unable to determine frequency, returning data frame unfilled')\n",
    "        else:\n",
    "            if lookback:\n",
    "                end = datetime.now()\n",
    "                start = end - timedelta(days=lookback)\n",
    "                start_date = (start.year,start.month,start.day)\n",
    "                end_date = (end.year,end.month,end.day)\n",
    "            df = df.pipe(reindex, start_date, end_date, freq)\n",
    "    df.__dict__['metadata'] = meta\n",
    "    return df\n",
    "    \n",
    "\n",
    "def catalog():\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    Requests the CWMS catalog.  Returns a large dict and not easy \n",
    "    wade through, it would be easier to go to a dataquery site to find \n",
    "    what you are looking for http://www.nwd-wc.usace.army.mil/dd/common/dataquery/www/\n",
    "        \n",
    "    Arguments: \n",
    "    \n",
    "    Returns: dict\n",
    "    \n",
    "    \"\"\"\n",
    "    url = r'http://www.nwd-wc.usace.army.mil/dd/common/web_service/webexec/getjson?catalog=%5B%5D'\n",
    "    r = requests.get(url)\n",
    "    return json.loads(r.text)\n",
    "\n",
    "def site_catalog(site):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns a dictionary of CWMS data paths for a particular site\n",
    "    \n",
    "    Arguments:\n",
    "        site -- cwms site name, example TDDO\n",
    "    \n",
    "    Returns: \n",
    "        json.loads(r.text) -- dictionary of available site data\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    url = r'http://www.nwd-wc.usace.army.mil/dd/common/web_service/webexec/getjson?tscatalog=%5B%22SITE%22%5D'\n",
    "    url = url.replace('SITE', site.upper())\n",
    "    r = requests.get(url)\n",
    "    return json.loads(r.text)\n",
    "\n",
    " \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Snake River Total Dissolved Gas (TDG) Overview Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ignore the performance warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from collections import OrderedDict\n",
    "from datetime import datetime, timedelta\n",
    "from get_avgs import washington_method\n",
    "import numpy as np\n",
    "now = datetime.now()- timedelta(hours = 8)\n",
    "#start_date = (2017, 6, 1)\n",
    "#end_date = (2017, 8, 2)\n",
    "start_date = (2018, 4, 1)\n",
    "end_date = (now.year, now. month, now.day-1)\n",
    "start_index = '-'.join([str(x) for x in start_date])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "\n",
    "tuples = [\n",
    "    \n",
    "    ('Lower Granite', 'Spill Cap', 'Starting → Change', 'kcfs'),\n",
    "    ('Lower Granite', 'Actual Spill', 'Daily Average', 'kcfs'),\n",
    "    ('Lower Granite', 'TW', 'LGNW', '% sat' ),\n",
    "    ('Lower Granite', 'd/s FB', 'LGSA', '% sat'),\n",
    "    \n",
    "    ('Little Goose', 'Spill Cap', 'Starting → Change', 'kcfs'),\n",
    "    ('Little Goose', 'Actual Spill', 'Daily Average', 'kcfs'),\n",
    "    ('Little Goose', 'TW', 'LGSW', '% sat' ),\n",
    "    ('Little Goose', 'd/s FB', 'LMNA', '% sat'),\n",
    "    \n",
    "    ('Lower Monumental', 'Spill Cap', 'Starting → Change', 'kcfs'),\n",
    "    ('Lower Monumental', 'Actual Spill', 'Daily Average', 'kcfs'),\n",
    "    ('Lower Monumental', 'TW', 'LMNW', '% sat' ),\n",
    "    ('Lower Monumental', 'd/s FB', ' IHRA ', '% sat'),\n",
    "    \n",
    "    ('Ice Harbor', 'Spill Cap', 'Starting → Change', 'kcfs'),\n",
    "    ('Ice Harbor', 'Actual Spill', 'Daily Average', 'kcfs'),\n",
    "    ('Ice Harbor', 'TW', 'IDSW', '% sat' ),\n",
    "    ('Ice Harbor', 'Pasco', 'PAQW', '% sat' ),\n",
    "    ('Ice Harbor', 'd/s FB', 'MCNA', '% sat'),\n",
    "]\n",
    "\n",
    "columns = pd.MultiIndex.from_tuples(tuples, names = ['Project','','','units'])\n",
    "\n",
    "paths = [\n",
    "    \n",
    "        'LWG.Flow-Spill-Cap-Fish.Inst.~1Day.0.CENWDP-COMPUTED-PUB', \n",
    "        'LWG.Flow-Spill.Ave.1Hour.1Hour.CBT-REV',\n",
    "        'LGNW.%-Saturation-TDG.Ave.~1Day.12Hours.CENWDP-COMPUTED-WAmethod-REV',\n",
    "        'LGSA.%-Saturation-TDG.Ave.~1Day.12Hours.CENWDP-COMPUTED-WAmethod-REV',\n",
    "        \n",
    "        'LGS.Flow-Spill-Cap-Fish.Inst.~1Day.0.CENWDP-COMPUTED-PUB', \n",
    "        'LGS.Flow-Spill.Ave.1Hour.1Hour.CBT-REV',\n",
    "        'LGSW.%-Saturation-TDG.Ave.~1Day.12Hours.CENWDP-COMPUTED-WAmethod-REV',\n",
    "        'LMNA.%-Saturation-TDG.Ave.~1Day.12Hours.CENWDP-COMPUTED-WAmethod-REV',\n",
    "         \n",
    "        'LMN.Flow-Spill-Cap-Fish.Inst.~1Day.0.CENWDP-COMPUTED-PUB', \n",
    "        'LMN.Flow-Spill.Ave.1Hour.1Hour.CBT-REV',\n",
    "        'LMNW.%-Saturation-TDG.Ave.~1Day.12Hours.CENWDP-COMPUTED-WAmethod-REV',\n",
    "        'IHRA.%-Saturation-TDG.Ave.~1Day.12Hours.CENWDP-COMPUTED-WAmethod-REV',\n",
    "    \n",
    "        'IHR.Flow-Spill-Cap-Fish.Inst.~1Day.0.CENWDP-COMPUTED-PUB', \n",
    "        'IHR.Flow-Spill.Ave.1Hour.1Hour.CBT-REV',\n",
    "        'IDSW.%-Saturation-TDG.Ave.~1Day.12Hours.CENWDP-COMPUTED-WAmethod-REV',\n",
    "        'PAQW.%-Saturation-TDG.Inst.1Hour.0.GOES-COMPUTED-REV',\n",
    "        'MCNA.%-Saturation-TDG.Ave.~1Day.12Hours.CENWDP-COMPUTED-WAmethod-REV',\n",
    "        \n",
    "        ]\n",
    "\n",
    "\n",
    "index = pd.date_range(start='-'.join([str(x) for x in start_date]), end='-'.join([str(x) for x in end_date]),  freq='D', name='date')\n",
    "df = pd.DataFrame(columns = columns, data = np.nan, index = index)\n",
    "meta = {}\n",
    "for path, column in zip(paths, tuples):\n",
    "    data = get_cwms(path, start_date = start_date, end_date = end_date, public = True, fill = False)\n",
    "    if isinstance(data,pd.DataFrame):\n",
    "        meta.update(data.__dict__['metadata'])\n",
    "        data = data.groupby(pd.Grouper(freq = 'D')).mean()\n",
    "        df[column] = data.iloc[:,0]\n",
    "    else: continue\n",
    "df = df.round(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "\"\"\"\n",
    "Questionable data is defined as values that are missing 1/3 or more data for calculation\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "column_dict = {\n",
    "                'LGNW': ('Lower Granite','TW'),\n",
    "                'LGSA': ('Lower Granite', 'd/s FB'),\n",
    "                'LGSW': ('Little Goose', 'TW'),\n",
    "                'LMNA': ('Little Goose', 'd/s FB'),\n",
    "                'LMNW': ('Lower Monumental', 'TW'), \n",
    "                'IHRA': ('Lower Monumental', 'd/s FB'),\n",
    "                'IDSW': ('Ice Harbor', 'TW'),\n",
    "                'PAQW': ('Ice Harbor','Pasco'),\n",
    "                'MCNA': ('Ice Harbor', 'd/s FB'),\n",
    "              }\n",
    "\n",
    "\n",
    "site_list = list(column_dict.keys())\n",
    "path = '.%-Saturation-TDG.Inst.1Hour.0.GOES-COMPUTED-REV '\n",
    "site_list = [x+path for x in site_list]\n",
    "questionable = pd.DataFrame(index = df.index, columns = df.columns, data = False)\n",
    "wash_start = datetime(*start_date) - timedelta(days = 10)\n",
    "wash_start = (wash_start.year, wash_start.month, wash_start.day)\n",
    "wash_end = (end_date[0], end_date[1], end_date[2] +1)\n",
    "for key, value in column_dict.items():\n",
    "    p = key+path\n",
    "    data = get_cwms(p, start_date=wash_start, end_date=wash_end, public = True, fill = False)\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        series = data.iloc[:,0]\n",
    "        wash = series.pipe(washington_method)\n",
    "        wash.index = [x.replace(hour = 0, minute = 0, second = 0) for x in wash.index]\n",
    "        wash.index.name = 'date'\n",
    "        wash = wash.loc[df.index]\n",
    "        quality = wash['wa_quality'] != True\n",
    "        questionable[value] = quality \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Get the meta dictionary keys match the column names so can be used below\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "paths.insert(-1,'PAQW.%-Saturation-TDG.Inst.1Hour.0.GOES-COMPUTED-RAW')\n",
    "p = []\n",
    "for path in paths:\n",
    "    column_name = '_'.join(path.split('.')[:2])\n",
    "    column_name = '_'.join(column_name.split('-'))\n",
    "    p.append(column_name)\n",
    "    \n",
    "meta_col_dict = {key:value for key,value in zip(p, list(df.columns))}\n",
    "temp_meta = {}\n",
    "for key, value in meta.items():\n",
    "    \n",
    "    try:\n",
    "        temp_meta.update({meta_col_dict[key]: value})\n",
    "    except KeyError:\n",
    "        continue\n",
    "        \n",
    "meta.update(temp_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "\"\"\"\n",
    "Lack of Load or involuntary spill: 6 hours of 24 hours that the project is spilling above the voluntary spill cap\n",
    "This will be the asteriks on the actual spill columns\n",
    "\n",
    "\n",
    "\n",
    "From the urban dictionary: asteriks\n",
    "Incorrect pronounciation of the word 'asterisk'. Use of the word 'asteriks' is a result of the USA's substandard education system.\n",
    "Jim: Hey Lou, what's that star thingy called that you get from pressing SHIFT + 8? \n",
    "\n",
    "Lou: an asteriks \n",
    "\n",
    "Jim: Aha! I knew you were a dumbass.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "site_dict = OrderedDict([\n",
    "            ('Lower Granite',['LWG']),\n",
    "            ('Little Goose',['LGS']),\n",
    "            ('Lower Monumental', ['LMN']),\n",
    "            ('Ice Harbor', ['IHR'])\n",
    "          ])\n",
    "\n",
    "column_dict = {\n",
    "    'LWG': 'Lower Granite',\n",
    "    'LGS': 'Little Goose',\n",
    "    'LMN': 'Lower Monumental',\n",
    "    'IHR': 'Ice Harbor'\n",
    "    \n",
    "}\n",
    "\n",
    "# Collecting the daily spill caps to compare against the hourly spill\n",
    "site_list = list(sum(site_dict.values(), []))\n",
    "spill_cap_path = '.Flow-Spill-Cap-Fish.Inst.~1Day.0.CENWDP-COMPUTED-PUB'\n",
    "spill_cap_list = [x+spill_cap_path for x in site_list]\n",
    "\n",
    "spill_cap = get_cwms(spill_cap_list, public = True, fill = False, start_date=start_date, end_date=end_date, timezone = 'PST')\n",
    "if isinstance(spill_cap, pd.DataFrame):\n",
    "    spill_cap.columns = [x.split('_')[0] for x in spill_cap.columns]\n",
    "    spill_cap.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "\n",
    "    # Collecting the hourly spill to compare against the daily spill caps\n",
    "    spill_path = '.Flow-Spill.Ave.1Hour.1Hour.CBT-REV'\n",
    "    spill_list = [x+spill_path for x in site_list]\n",
    "\n",
    "    spill = get_cwms(spill_list, public = True, start_date=start_date, end_date=end_date, timezone = 'PST', fill = False)\n",
    "    spill.columns = [x.split('_')[0] for x in spill.columns]\n",
    "    spill.rename(columns = column_dict, inplace = True)\n",
    "\n",
    "    # Group the data by day to check if the project was in involuntary spill\n",
    "    sg = spill.groupby(pd.Grouper(level='date', freq='D'))\n",
    "    scg = spill_cap.groupby(pd.Grouper(level='date', freq='D')).mean().groupby(pd.Grouper(level='date', freq='D'))\n",
    "    date = list(scg.groups.keys())\n",
    "    inv_spill = pd.DataFrame(index = date, columns = spill.columns)\n",
    "    for group, value in scg:\n",
    "        g = sg.get_group(group)\n",
    "        s = value.iloc[0]\n",
    "        inv_spill.loc[group] = g.apply(lambda x: x.gt(s), axis = 1).sum()>5\n",
    "\n",
    "    \"\"\"\n",
    "    Create boolean df for asterik\n",
    "    \"\"\"    \n",
    "\n",
    "\n",
    "    projects = list(set(df.columns.get_level_values(0).tolist()))\n",
    "    inv_spill_bool = pd.DataFrame(data = False,index = df.index, columns = df.columns)\n",
    "    for project in projects:\n",
    "        inv_spill_bool.loc[:,(project, 'Actual Spill')] = inv_spill[project]\n",
    "\n",
    "    inv_spill_bool.fillna(value = False, inplace = True)\n",
    "else: inv_spill_bool = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Minimum Generation: at least 6 hours of 24 that the project is at minimum generation\n",
    "This will be the green on the actual spill columns\n",
    "\"\"\"\n",
    "min_gen_dict_kcfs = OrderedDict([\n",
    "            ('Lower Granite',13.2),\n",
    "            ('Little Goose',12.0),\n",
    "            ('Lower Monumental', 12.5),\n",
    "            ('Ice Harbor', 10.0)\n",
    "          ])\n",
    "\n",
    "min_gen_kcfs = pd.Series(min_gen_dict_kcfs)\n",
    "\n",
    "# Collecting the daily generation flow to compare against the minimum generation flow, group by day\n",
    "site_list = list(sum(site_dict.values(), []))\n",
    "gen_flow_path = '.Flow-Gen.Ave.1Hour.1Hour.CBT-REV'\n",
    "gen_flow_list = [x+gen_flow_path for x in site_list]\n",
    "gen_flow = get_cwms(gen_flow_list, public = True, start_date=start_date, end_date=end_date, timezone = 'PST', fill = False)\n",
    "gen_flow.columns = [x.split('_')[0] for x in gen_flow.columns]\n",
    "gen_flow.rename(columns = column_dict, inplace = True)\n",
    "gen_flow_grouped = gen_flow.groupby(pd.Grouper(level='date', freq='D'))\n",
    " \n",
    "    \n",
    "# Creat a df fill with min gen data as dummy data\n",
    "date = list(gen_flow_grouped.groups.keys())\n",
    "min_gen = pd.DataFrame(index = date)\n",
    "for key, value in min_gen_kcfs.items():\n",
    "    min_gen[key] = value\n",
    "\n",
    "#check if proj in min generation for the day and fill min_gen with result  \n",
    "min_gen.index.rename('date', inplace = True)\n",
    "min_gen_grouped = min_gen.groupby(pd.Grouper(level='date', freq='D'))\n",
    "for group, value in gen_flow_grouped:\n",
    "    min_gen.loc[group] = value.apply(lambda x: x <= min_gen_kcfs, axis = 1).sum()>5\n",
    "\n",
    "\"\"\"\n",
    "Create boolean df for css\n",
    "\"\"\"    \n",
    "    \n",
    "    \n",
    "projects = list(set(df.columns.get_level_values(0).tolist()))\n",
    "min_gen_bool = pd.DataFrame(data = False,index = df.index, columns = df.columns)\n",
    "for project in projects:\n",
    "    min_gen_bool.loc[:,(project, 'Actual Spill')] = min_gen[project]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Not Meeting TDG Gas Cap Tailwater: defined as combined OR WA value > 120.5\n",
    "Not Meeting TDG Gas Cap Forebay: defined as combined OR WA value > 115.5\n",
    "This will be the blue on the TW and downstream forebay columns\n",
    "\"\"\"\n",
    "idx = pd.IndexSlice\n",
    "gas_cap_exceeds = df.copy()\n",
    "tw = gas_cap_exceeds.sort_index(axis = 1).loc[:,pd.IndexSlice[:,'TW']]\n",
    "fb = gas_cap_exceeds.sort_index(axis = 1).loc[:,pd.IndexSlice[:,'d/s FB']]\n",
    "gas_cap_exceeds[tw.columns] = tw.applymap(lambda x: x > 120.5)\n",
    "gas_cap_exceeds[fb.columns] = fb.applymap(lambda x: x > 115.5)\n",
    "gas_cap_exceeds = gas_cap_exceeds.sort_index(axis=1)[df.columns]\n",
    "gas_cap_exceeds = gas_cap_exceeds.applymap(lambda x: x if type(x) == bool else False)\n",
    "gas_cap_exceeds.head()\n",
    "\n",
    "\"\"\"\n",
    "Combine gas cap by project: If true in one gauge, true for all project, except Ice Harbor special case\n",
    "\"\"\"\n",
    "\n",
    "gas_cap_by_gauge =  pd.DataFrame(data = False,index = gas_cap_exceeds.index, columns = gas_cap_exceeds.columns)\n",
    "projects = list(set(df.columns.get_level_values(0).tolist()))\n",
    "for project in projects:\n",
    "    data = gas_cap_exceeds.loc[:,project].sort_index(axis=1).loc[idx[:,['TW', 'd/s FB']]]\n",
    "    gas_cap_by_gauge.loc[:,(project, 'TW')] = data.apply(lambda x: x.any(),axis = 1)\n",
    "    gas_cap_by_gauge.loc[:,(project, 'd/s FB')] = data.apply(lambda x: x.any(),axis = 1)\n",
    "gas_cap_by_gauge['Ice Harbor'] = gas_cap_exceeds['Ice Harbor']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Most restrictive gauge defined as:\n",
    "\n",
    "Bold tailrace if:\n",
    "(Tailrace TDG -120) > (ds Forebay -115)\n",
    "Else:\n",
    "Bold ds Forebay\n",
    "\n",
    "Bold regardless of TDG value (above or below target).\n",
    "\n",
    "\n",
    "This is the updated bold bold \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "most_restrictive_gauge = df.copy()\n",
    "tw = most_restrictive_gauge.sort_index(axis = 1).loc[:,pd.IndexSlice[:,'TW']]\n",
    "fb = most_restrictive_gauge.sort_index(axis = 1).loc[:,pd.IndexSlice[:,'d/s FB']]\n",
    "\n",
    "\n",
    "\n",
    "most_restrictive_gauge[tw.columns] = (tw - 120).values > (fb - 115).values\n",
    "most_restrictive_gauge[fb.columns] = (tw - 120).values < (fb - 115).values\n",
    "\n",
    "\n",
    "most_restrictive_gauge = most_restrictive_gauge.sort_index(axis=1)[df.columns]\n",
    "most_restrictive_gauge = most_restrictive_gauge.applymap(lambda x: x if type(x) == bool else False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#\"\"\"\n",
    "#Gas cap meets TW: defined as combined OR WA value > 119\n",
    "#Gas cap meets FB: defined as combined OR WA value > 114\n",
    "\n",
    "#This will be the bold on the TW and downstream forebay columns\n",
    "#\"\"\"\n",
    "#idx = pd.IndexSlice\n",
    "#gas_cap_meets = df.copy()\n",
    "#tw = gas_cap_meets.sort_index(axis = 1).loc[:,pd.IndexSlice[:,'TW']]\n",
    "#fb = gas_cap_meets.sort_index(axis = 1).loc[:,pd.IndexSlice[:,'d/s FB']]\n",
    "#gas_cap_meets[tw.columns] = tw.applymap(lambda x: x >= 119)\n",
    "#gas_cap_meets[fb.columns] = fb.applymap(lambda x: x >= 114)\n",
    "#gas_cap_meets = gas_cap_meets.sort_index(axis=1)[df.columns]\n",
    "#gas_cap_meets = gas_cap_meets.applymap(lambda x: x if type(x) == bool else False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert the dataframe to string because it displays better, remove decimals, add the asterik, and format the index to be date only (no time), for all dataframes.  \n",
    "If index not formated for all df's the styling will not work\n",
    "\"\"\"\n",
    "\n",
    "df_string = df.copy().round(0).astype(str).applymap(lambda x: x.replace('.0', ''))\n",
    "if isinstance(inv_spill_bool, pd.DataFrame):\n",
    "    df_string[inv_spill_bool] = df_string[inv_spill_bool] + '*'\n",
    "df_string.replace('nan', '--', inplace = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "spill_cap = df_string.sort_index(axis = 1).loc[:,pd.IndexSlice[:,'Spill Cap']].copy()\n",
    "for column in spill_cap.columns:\n",
    "    series = spill_cap[column]\n",
    "    for index,value in enumerate(series[1:]):\n",
    "        previous_value = series[index]\n",
    "        if value != previous_value:\n",
    "            df_string[column][index+1] = ('{}{}{}'.format(str(previous_value), '→', str(value)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for dataframe in [df_string,gas_cap_by_gauge,min_gen_bool, most_restrictive_gauge, questionable]:\n",
    "    dataframe.index = dataframe.index.strftime('%Y-%m-%d')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Custom css\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def hover(hover_color=\"#ffff99\"):\n",
    "    return dict(selector=\"tbody tr:hover\",\n",
    "                props=[(\"background-color\", \"%s\" % hover_color)])\n",
    "\n",
    "styles = [\n",
    "    \n",
    "   \n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "table key\n",
    "\"\"\"\n",
    "\n",
    "blue = '#7194da'\n",
    "green = '#cfff95'\n",
    "\n",
    "def highlight(value):\n",
    "    return table_css.applymap(lambda x: x)\n",
    "key_list =[\n",
    "            'Most restrictive gauge used to determine spill cap',\n",
    "            'Project spilling above the voluntary spill cap for 6 or more hours',\n",
    "            'At least one TDG value exceeds max limit',\n",
    "            'Project operating at minimum generation for 6 or more hours',\n",
    "            '1/3 of data or more missing for value calculation',\n",
    "            'No data'\n",
    "        ]\n",
    "table_key = pd.DataFrame({'Table Key':key_list })                         \n",
    "table_key.set_index('Table Key', inplace = True)\n",
    "table_key['value']=['value','*','','','value', '--']\n",
    "table_css = pd.DataFrame({'Table Key':key_list,'value':['font-weight: 900',\\\n",
    "                                                        '',\\\n",
    "                                                        'background-color: ' + blue,\\\n",
    "                                                        'background-color: '+ green, \\\n",
    "                                                        'color: red',\n",
    "                                                        '']})\n",
    "table_css.set_index('Table Key', inplace = True)\n",
    "table_key.style.apply(highlight, axis = None)\n",
    "\n",
    "\n",
    "hide_index = [{'selector': '.row_heading, .blank', 'props': [('display', 'none;')]}]\n",
    "key_styles = styles # + hide_index\n",
    "key_html = (table_key.style)\n",
    "key_html.apply(highlight,axis = None).set_uuid('key')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding table styles\n",
    "\"\"\"\n",
    "\n",
    "def tbl_css(value,css,df):\n",
    "    return df.applymap(lambda x: css if x else '')\n",
    "\n",
    "s = df_string.style\n",
    "\n",
    "table_styles = styles + [hover()]\n",
    "\n",
    "html = (\n",
    "          s.set_table_styles(table_styles)\n",
    "          .set_caption(\"Spill Cap changes occur at 16:00 PST.\")\n",
    "       )\n",
    "\n",
    "html \\\n",
    ".apply(tbl_css, css = 'font-weight: 900', df = most_restrictive_gauge, axis = None) \\\n",
    ".apply(tbl_css, css = 'background-color: #7194da', df = gas_cap_by_gauge, axis = None) \\\n",
    ".apply(tbl_css, css = 'background-color: #cfff95', df = min_gen_bool, axis = None)\\\n",
    ".apply(tbl_css, css = 'color: red', df = questionable, axis = None) \\\n",
    ".set_uuid('data_table')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame().style.set_table_styles(table_styles).set_uuid('header-fixed')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
